{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('new_appdata10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Independent and Response Variables\n",
    "response = dataset[\"enrolled\"]\n",
    "dataset = dataset.drop(columns=\"enrolled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, response,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Identifiers\n",
    "train_identity = X_train['user']\n",
    "X_train = X_train.drop(columns = ['user'])\n",
    "test_identity = X_test['user']\n",
    "X_test = X_test.drop(columns = ['user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train)) #fit_transform return numpy array\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test)) #fit_transform lose column name and index\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>age</th>\n",
       "      <th>numscreens</th>\n",
       "      <th>minigame</th>\n",
       "      <th>used_premium_feature</th>\n",
       "      <th>liked</th>\n",
       "      <th>location</th>\n",
       "      <th>Institutions</th>\n",
       "      <th>VerifyPhone</th>\n",
       "      <th>...</th>\n",
       "      <th>SecurityModal</th>\n",
       "      <th>ResendToken</th>\n",
       "      <th>TransactionList</th>\n",
       "      <th>NetworkFailure</th>\n",
       "      <th>ListPicker</th>\n",
       "      <th>Other</th>\n",
       "      <th>SavingCount</th>\n",
       "      <th>CMCount</th>\n",
       "      <th>CCCount</th>\n",
       "      <th>LoansCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20330</th>\n",
       "      <td>-0.504961</td>\n",
       "      <td>1.000837</td>\n",
       "      <td>0.025525</td>\n",
       "      <td>-1.026726</td>\n",
       "      <td>-0.346830</td>\n",
       "      <td>2.186018</td>\n",
       "      <td>2.246319</td>\n",
       "      <td>-1.039218</td>\n",
       "      <td>-0.644848</td>\n",
       "      <td>-1.052581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119697</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.115879</td>\n",
       "      <td>-0.091207</td>\n",
       "      <td>-0.087221</td>\n",
       "      <td>-1.147303</td>\n",
       "      <td>-0.260877</td>\n",
       "      <td>-0.763372</td>\n",
       "      <td>-0.289185</td>\n",
       "      <td>1.785389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17532</th>\n",
       "      <td>-0.997389</td>\n",
       "      <td>1.135280</td>\n",
       "      <td>-0.898034</td>\n",
       "      <td>1.328829</td>\n",
       "      <td>2.883254</td>\n",
       "      <td>-0.457453</td>\n",
       "      <td>-0.445173</td>\n",
       "      <td>0.962262</td>\n",
       "      <td>1.550753</td>\n",
       "      <td>0.950046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119697</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.115879</td>\n",
       "      <td>-0.091207</td>\n",
       "      <td>-0.087221</td>\n",
       "      <td>1.839740</td>\n",
       "      <td>-0.260877</td>\n",
       "      <td>0.057524</td>\n",
       "      <td>-0.289185</td>\n",
       "      <td>0.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45819</th>\n",
       "      <td>-1.489818</td>\n",
       "      <td>-1.150250</td>\n",
       "      <td>-0.528611</td>\n",
       "      <td>4.066366</td>\n",
       "      <td>2.883254</td>\n",
       "      <td>-0.457453</td>\n",
       "      <td>-0.445173</td>\n",
       "      <td>-1.039218</td>\n",
       "      <td>1.550753</td>\n",
       "      <td>-1.052581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119697</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.115879</td>\n",
       "      <td>-0.091207</td>\n",
       "      <td>-0.087221</td>\n",
       "      <td>1.025092</td>\n",
       "      <td>-0.260877</td>\n",
       "      <td>0.878421</td>\n",
       "      <td>1.336593</td>\n",
       "      <td>1.785389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34807</th>\n",
       "      <td>0.479896</td>\n",
       "      <td>0.059736</td>\n",
       "      <td>-0.620967</td>\n",
       "      <td>0.182883</td>\n",
       "      <td>2.883254</td>\n",
       "      <td>-0.457453</td>\n",
       "      <td>-0.445173</td>\n",
       "      <td>0.962262</td>\n",
       "      <td>-0.644848</td>\n",
       "      <td>-1.052581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119697</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.115879</td>\n",
       "      <td>-0.091207</td>\n",
       "      <td>-0.087221</td>\n",
       "      <td>1.025092</td>\n",
       "      <td>-0.260877</td>\n",
       "      <td>-0.763372</td>\n",
       "      <td>-0.289185</td>\n",
       "      <td>0.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31888</th>\n",
       "      <td>-0.012532</td>\n",
       "      <td>0.463065</td>\n",
       "      <td>1.687932</td>\n",
       "      <td>-0.644744</td>\n",
       "      <td>-0.346830</td>\n",
       "      <td>-0.457453</td>\n",
       "      <td>-0.445173</td>\n",
       "      <td>0.962262</td>\n",
       "      <td>-0.644848</td>\n",
       "      <td>0.950046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119697</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.115879</td>\n",
       "      <td>-0.091207</td>\n",
       "      <td>-0.087221</td>\n",
       "      <td>-0.875753</td>\n",
       "      <td>-0.260877</td>\n",
       "      <td>0.878421</td>\n",
       "      <td>-0.289185</td>\n",
       "      <td>-1.165789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dayofweek      hour       age  numscreens  minigame  \\\n",
       "20330  -0.504961  1.000837  0.025525   -1.026726 -0.346830   \n",
       "17532  -0.997389  1.135280 -0.898034    1.328829  2.883254   \n",
       "45819  -1.489818 -1.150250 -0.528611    4.066366  2.883254   \n",
       "34807   0.479896  0.059736 -0.620967    0.182883  2.883254   \n",
       "31888  -0.012532  0.463065  1.687932   -0.644744 -0.346830   \n",
       "\n",
       "       used_premium_feature     liked  location  Institutions  VerifyPhone  \\\n",
       "20330              2.186018  2.246319 -1.039218     -0.644848    -1.052581   \n",
       "17532             -0.457453 -0.445173  0.962262      1.550753     0.950046   \n",
       "45819             -0.457453 -0.445173 -1.039218      1.550753    -1.052581   \n",
       "34807             -0.457453 -0.445173  0.962262     -0.644848    -1.052581   \n",
       "31888             -0.457453 -0.445173  0.962262     -0.644848     0.950046   \n",
       "\n",
       "       ...  SecurityModal  ResendToken  TransactionList  NetworkFailure  \\\n",
       "20330  ...      -0.119697     -0.11742        -0.115879       -0.091207   \n",
       "17532  ...      -0.119697     -0.11742        -0.115879       -0.091207   \n",
       "45819  ...      -0.119697     -0.11742        -0.115879       -0.091207   \n",
       "34807  ...      -0.119697     -0.11742        -0.115879       -0.091207   \n",
       "31888  ...      -0.119697     -0.11742        -0.115879       -0.091207   \n",
       "\n",
       "       ListPicker     Other  SavingCount   CMCount   CCCount  LoansCount  \n",
       "20330   -0.087221 -1.147303    -0.260877 -0.763372 -0.289185    1.785389  \n",
       "17532   -0.087221  1.839740    -0.260877  0.057524 -0.289185    0.309800  \n",
       "45819   -0.087221  1.025092    -0.260877  0.878421  1.336593    1.785389  \n",
       "34807   -0.087221  1.025092    -0.260877 -0.763372 -0.289185    0.309800  \n",
       "31888   -0.087221 -0.875753    -0.260877  0.878421 -0.289185   -1.165789  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, penalty = 'l1')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>predicted_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239786</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>207226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>363062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>152296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>359940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>136089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14231</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>216038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18918</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>316730</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>228387</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69640</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>358264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>348059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>178743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>167556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>294101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>192801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>163983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>298830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>151790</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>348989</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>248593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>316086</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>192540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>256833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>273991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>365937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>295129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>255715</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>37332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>164886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>309967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>14907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>244737</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>284862</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>60719</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>262103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>243679</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>280000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>255074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>347521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>335029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>37271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>240006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>279449</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>143036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>91158</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>248318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>142418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>279355</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  enrolled  predicted_results\n",
       "0     239786         1                  1\n",
       "1     279644         1                  1\n",
       "2      98290         0                  0\n",
       "3     170150         1                  1\n",
       "4     237568         1                  1\n",
       "5      65042         1                  0\n",
       "6     207226         1                  1\n",
       "7     363062         0                  0\n",
       "8     152296         1                  1\n",
       "9      64484         0                  0\n",
       "10     38108         1                  1\n",
       "11    359940         0                  0\n",
       "12    136089         0                  0\n",
       "13     14231         1                  1\n",
       "14    216038         0                  0\n",
       "15     18918         1                  1\n",
       "16    316730         1                  1\n",
       "17     28308         1                  0\n",
       "18    228387         1                  0\n",
       "19     69640         1                  1\n",
       "20    358264         0                  0\n",
       "21    348059         0                  0\n",
       "22    178743         1                  1\n",
       "23    167556         0                  0\n",
       "24    294101         0                  0\n",
       "25    192801         0                  1\n",
       "26    163983         1                  1\n",
       "27    298830         0                  0\n",
       "28    151790         1                  1\n",
       "29     20200         1                  1\n",
       "...      ...       ...                ...\n",
       "9970  348989         0                  1\n",
       "9971  248593         1                  0\n",
       "9972  316086         1                  1\n",
       "9973  192540         1                  1\n",
       "9974  256833         0                  0\n",
       "9975  273991         1                  1\n",
       "9976  365937         0                  0\n",
       "9977  295129         0                  0\n",
       "9978  255715         1                  0\n",
       "9979   37332         0                  1\n",
       "9980  164886         1                  1\n",
       "9981  309967         0                  1\n",
       "9982   14907         0                  0\n",
       "9983  244737         1                  1\n",
       "9984  284862         0                  1\n",
       "9985   60719         1                  1\n",
       "9986  262103         1                  0\n",
       "9987  243679         1                  1\n",
       "9988  280000         1                  1\n",
       "9989  255074         0                  0\n",
       "9990  347521         0                  0\n",
       "9991  335029         1                  0\n",
       "9992   37271         1                  0\n",
       "9993  240006         1                  1\n",
       "9994  279449         0                  1\n",
       "9995  143036         1                  0\n",
       "9996   91158         1                  1\n",
       "9997  248318         0                  0\n",
       "9998  142418         1                  1\n",
       "9999  279355         1                  1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.concat([y_test, test_identity], axis = 1).dropna()\n",
    "final_results['predicted_results'] = y_pred\n",
    "final_results[['user', 'enrolled', 'predicted_results']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7681\n",
      "0.7618952017667135\n",
      "0.7700892857142857\n",
      "0.7659703300030276\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred)) # tp / (tp + fp)\n",
    "print(recall_score(y_test, y_pred)) # tp / (tp + fn)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy: 0.7681\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (6, 4))\n",
    "sn.set(font_scale=1.2)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator= classifier, X= X_train, y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.767 (+/- 0.010)\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search (Round 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 74.20 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Select Regularization Method\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# Combine Parameters\n",
    "parameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7674, {'C': 0.01, 'penalty': 'l2'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search (Round 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 39.53 seconds\n"
     ]
    }
   ],
   "source": [
    "# Select Regularization Method\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = [0.1, 0.5, 0.9, 1, 2, 5]\n",
    "\n",
    "# Combine Parameters\n",
    "parameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767225"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
